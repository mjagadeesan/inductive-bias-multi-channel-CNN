{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "macro-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Loading training and test data\n",
    "import torch\n",
    "\n",
    "data_tr = torch.load(\"training_data_nonlinear.txt\")\n",
    "target_tr = torch.load(\"training_targets_nonlinear.txt\")\n",
    "data_test = torch.load(\"test_data_nonlinear.txt\")\n",
    "target_test = torch.load(\"test_targets_nonlinear.txt\")\n",
    "\n",
    "num_samples = 512\n",
    "num_samples_test = 100 # number of test samples\n",
    "# new_dim1 = 28 * 1 # first dimension\n",
    "# new_dim2 = 28 * 1 # second dimension\n",
    "# old_dim = 28 # MNIST original dimension\n",
    "\n",
    "new_dim1 = 32 # first dimension\n",
    "new_dim2 = 32 # second dimension\n",
    "old_dim = 32 # CIFAR original dimension\n",
    "\n",
    "print(data_tr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "pursuant-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Two-layer linear convolutional neural network\n",
    "output_channels = 1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, ker_size1, ker_size2, output_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.ker_size1 = ker_size1\n",
    "        self.ker_size2 = ker_size2\n",
    "        self.output_channels = output_channels\n",
    "        self.conv1 = nn.Conv2d(1, output_channels, kernel_size=(self.ker_size1, self.ker_size2), bias=False) \n",
    "        self.fc1 = nn.Linear(int(new_dim1 * new_dim2 * output_channels), 1, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = F.pad(x, (0,self.ker_size2-1,0,self.ker_size1-1), mode='circular') # Circular padding \n",
    "        y1 = self.conv1(y1)\n",
    "        y1 = F.relu(y1) # ReLU activations\n",
    "        y1 = y1.reshape(y1.size(0), -1)\n",
    "        y1 = self.fc1(y1) \n",
    "        return y1\n",
    "\n",
    "    def initialize(self, initialization_scale, ker_size1):\n",
    "        nn.init.normal_(self.fc1.weight, mean=0.0, std=initialization_scale/np.sqrt(new_dim1))\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=initialization_scale/np.sqrt(ker_size1))\n",
    "\n",
    "\n",
    "output = torch.zeros((num_samples, 1))\n",
    "output = output.float()\n",
    "output_test = torch.zeros((num_samples_test, 1))\n",
    "output_test = output.float()\n",
    "\n",
    "\n",
    "# Batch gradient descent\n",
    "def train_minibatch(network, optimizer):\n",
    "    minibatch_size = 512\n",
    "    num_batch = int(num_samples/minibatch_size)\n",
    "    for i in range(num_batch):\n",
    "        network.train()\n",
    "        optimizer.zero_grad()\n",
    "        start_index = i * minibatch_size\n",
    "        end_index = start_index + minibatch_size\n",
    "        output = network(data_tr[start_index:end_index])\n",
    "        loss = torch.sum(torch.exp(-1 * torch.mul(output.flatten(), target_tr[start_index:end_index]))) / minibatch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate training data loss\n",
    "def train_eval(network):\n",
    "    network.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        output = network(data_tr)\n",
    "        train_loss = torch.sum(torch.exp(-1 * torch.mul(output.flatten(), target_tr)))\n",
    "        pred = output.apply_(lambda x: 1 if x > 0 else -1)\n",
    "        correct += pred.eq(target_tr.data.view_as(pred)).sum()\n",
    "    train_loss /= num_samples\n",
    "    print('\\nTrain set: Avg. loss: {:.9f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    train_loss, correct, num_samples,\n",
    "    100. * correct / num_samples))\n",
    "    return train_loss\n",
    "\n",
    "def test(network):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        output_test = network(data_test)\n",
    "        test_loss = torch.sum(torch.exp(-1 * torch.mul(output_test.flatten(), target_test)))\n",
    "        pred = output_test.apply_(lambda x: 1 if x > 0 else -1)\n",
    "        correct += pred.eq(target_test.data.view_as(pred)).sum()\n",
    "    test_loss /= num_samples_test\n",
    "    accuracy = 100. * correct / num_samples_test\n",
    "    losses = test_loss\n",
    "    return (accuracy, losses)\n",
    "\n",
    "\n",
    "# Get the information about beta\n",
    "def extract_info(network, show_photo): \n",
    "\n",
    "  # Compute beta for linear CNNs\n",
    "    beta_test = np.zeros((new_dim1,new_dim2))\n",
    "    for i in range(new_dim1):\n",
    "        for j in range(new_dim2):\n",
    "            tempimg = torch.zeros((1,1,new_dim1, new_dim2))\n",
    "            tempimg[0,0,i,j]=1\n",
    "            beta_test[i,j] = network(tempimg)  \n",
    "\n",
    "  # Compute margin\n",
    "    with torch.no_grad():\n",
    "        network.eval()\n",
    "        output_np = np.ndarray.flatten(network(data_tr).data.numpy())\n",
    "        target_np = np.ndarray.flatten(target_tr.data.numpy())\n",
    "        margins = [target_np[i] * output_np[i] for i in range(num_samples)]\n",
    "        min_margin = min(margins) # get the minimum margin for any datapoint \n",
    "\n",
    "\n",
    "    # Compute R(beta)\n",
    "    w1 = network.conv1.weight.detach().numpy()\n",
    "    w2 = network.fc1.weight.detach().numpy()\n",
    "    w1_norm_sq = np.sum(np.square(w1))\n",
    "    w2_norm_sq = np.sum(np.square(w2))\n",
    "    print(w1_norm_sq, w2_norm_sq)\n",
    "    Rbeta = (np.sum(np.square(w1)) + np.sum(np.square(w2))) * np.sqrt(new_dim1 * new_dim2)\n",
    "\n",
    "\n",
    "    # Normalize by margin \n",
    "    beta_test = beta_test / min_margin # normalize to have margin 1\n",
    "    hat_beta = np.absolute(np.fft.fft2(beta_test,norm='ortho'))\n",
    "    Rbeta = Rbeta / min_margin\n",
    "\n",
    "    print(\"l2 norm: \" + str(2 * np.sqrt(new_dim1 * new_dim2)* np.linalg.norm(beta_test, ord=\"fro\")))\n",
    "    print(\"l1 norm: \" + str(2 * np.sum(hat_beta)))\n",
    "    print(\"Rbeta: \" + str(Rbeta))\n",
    "\n",
    "    if show_photo:\n",
    "        print(\"Time domain:\")\n",
    "        plt.imshow(np.absolute(beta_test), cmap='gray')\n",
    "        plt.show()\n",
    "        print(\"Frequency domain:\")\n",
    "        plt.imshow(np.absolute(hat_beta), cmap='gray', norm=LogNorm(vmin=0.0001, vmax=0.08))\n",
    "        plt.show()\n",
    "  \n",
    "    return (Rbeta, beta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "alpha-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and extract info about beta\n",
    "import seaborn as sns\n",
    "n_epochs = 100000\n",
    "learning_rate_start = 0.001\n",
    "momentum = 0.3\n",
    "initialization_scale = 0.01\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "def experiment(ker_size1, ker_size2, output_channels):\n",
    "  # print(class1, class2)\n",
    "    network = Net(ker_size1, ker_size2, output_channels)\n",
    "    network.initialize(initialization_scale, ker_size1)\n",
    "    optimizer =  optim.SGD(network.parameters(), lr=learning_rate_start, momentum=momentum)\n",
    "    print(\"Before training:\")\n",
    "    train_eval(network)\n",
    "    extract_info(network, False)\n",
    "    # test()\n",
    "    \n",
    "    print(\"Start training:\")\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        train_minibatch(network, optimizer)\n",
    "        if epoch % 100 == 0:\n",
    "            loss = train_eval(network)\n",
    "            if loss <= 0.000001: # stop at 10^-6 loss \n",
    "                break\n",
    "            extract_info(network, False)\n",
    "        # After enough epochs, change the learning rate to be higher to expedite convergence\n",
    "\n",
    "        if epoch == 200 == 0:\n",
    "            optimizer =  optim.SGD(network.parameters(), lr=0.005, momentum=momentum)\n",
    "            print(\"Learning rate change\")\n",
    "              # optimizer =  optim.SGD(network.parameters(), lr=0.001, momentum=momentum)\n",
    "\n",
    "        if epoch == 500:\n",
    "            optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=momentum)\n",
    "            print(\"Learning rate change\")\n",
    "              # optimizer =  optim.SGD(network.parameters(), lr=0.001, momentum=momentum)\n",
    "\n",
    "#         if epoch == 1000:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=0.05, momentum=momentum)\n",
    "              # print(\"Learning rate change\")\n",
    "#               optimizer =  optim.SGD(network.parameters(), lr=0.005, momentum=momentum)\n",
    "\n",
    "#         if epoch == 2000:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=0.1, momentum=momentum)\n",
    "#               # optimizer =  optim.SGD(network.parameters(), lr=0.007, momentum=momentum)\n",
    "\n",
    "#         if epoch == 1500:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=0.5, momentum=momentum)\n",
    "\n",
    "#         if epoch == 2000:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=1, momentum=momentum)\n",
    "#               # optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=momentum)\n",
    "\n",
    "#         if epoch == 3000:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=2, momentum=momentum)\n",
    "#               # optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=momentum)\n",
    "\n",
    "#         if epoch == 4000:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=4, momentum=momentum)\n",
    "#               # optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=momentum)\n",
    "\n",
    "#         if epoch == 4500:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=10, momentum=momentum)\n",
    "\n",
    "#         if epoch == 5000:\n",
    "#             optimizer = optim.SGD(network.parameters(), lr=20, momentum=momentum)\n",
    "\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print(test(network))\n",
    "\n",
    "    print(\"After training:\")\n",
    "    train_eval(network)\n",
    "    (accuracy, losses) = test(network)\n",
    "    print(accuracy, losses)\n",
    "\n",
    "    (rk, beta) = extract_info(network, True)\n",
    "\n",
    "    return (rk, beta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "small-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "Before training:\n",
      "\n",
      "Train set: Avg. loss: 1.000190020, Accuracy: 256/512 (50%)\n",
      "\n",
      "0.00010345826 0.0034972348\n",
      "l2 norm: 2007.2675041343887\n",
      "l1 norm: 64.48817724794652\n",
      "Rbeta: -5.924707827639042\n",
      "Start training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-103218507942>:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm(range(1, n_epochs + 1)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16439021ee741e5af6587d650b4e694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Avg. loss: 1.000135422, Accuracy: 256/512 (50%)\n",
      "\n",
      "0.000102426406 0.003496228\n",
      "l2 norm: 2003.3998921941075\n",
      "l1 norm: 64.62280151034703\n",
      "Rbeta: -6.8148151577480744\n",
      "\n",
      "Train set: Avg. loss: 1.000091910, Accuracy: 256/512 (50%)\n",
      "\n",
      "0.00010411153 0.0034979384\n",
      "l2 norm: 1997.3589931938807\n",
      "l1 norm: 64.7558821346496\n",
      "Rbeta: -7.843903616293478\n",
      "\n",
      "Train set: Avg. loss: 1.000056744, Accuracy: 256/512 (50%)\n",
      "\n",
      "0.000108537766 0.003502389\n",
      "l2 norm: 1989.7938599883432\n",
      "l1 norm: 64.92423416848227\n",
      "Rbeta: -9.030754082056305\n",
      "\n",
      "Train set: Avg. loss: 1.000027061, Accuracy: 256/512 (50%)\n",
      "\n",
      "0.00011586953 0.003509745\n",
      "l2 norm: 1980.3780916501296\n",
      "l1 norm: 65.13841376430715\n",
      "Rbeta: -10.397147375473933\n",
      "\n",
      "Train set: Avg. loss: 1.000000715, Accuracy: 256/512 (50%)\n",
      "\n",
      "0.00012642205 0.0035203213\n",
      "l2 norm: 1968.7310390371651\n",
      "l1 norm: 65.41179452265732\n",
      "Rbeta: -11.966649931338038\n",
      "Learning rate change\n",
      "(tensor(50.), tensor(1.0000))\n",
      "\n",
      "Train set: Avg. loss: 0.962995172, Accuracy: 326/512 (64%)\n",
      "\n",
      "0.0870146 0.09075431\n",
      "l2 norm: 418.41273471387814\n",
      "l1 norm: 16.924677185109033\n",
      "Rbeta: -8.236304427277618\n",
      "\n",
      "Train set: Avg. loss: 0.910948634, Accuracy: 350/512 (68%)\n",
      "\n",
      "0.3915826 0.39739975\n",
      "l2 norm: 680.5530966658864\n",
      "l1 norm: 40.164677908145194\n",
      "Rbeta: -28.28148855191186\n",
      "\n",
      "Train set: Avg. loss: 0.812329650, Accuracy: 384/512 (75%)\n",
      "\n",
      "1.3709853 1.3786452\n",
      "l2 norm: 1046.238506280843\n",
      "l1 norm: 119.65597882387654\n",
      "Rbeta: -117.47824419200774\n",
      "\n",
      "Train set: Avg. loss: 0.693678141, Accuracy: 409/512 (80%)\n",
      "\n",
      "3.1230342 3.1331375\n",
      "l2 norm: 1468.5285650488806\n",
      "l1 norm: 291.63281005452825\n",
      "Rbeta: -314.70182937558593\n",
      "\n",
      "Train set: Avg. loss: nan, Accuracy: 256/512 (50%)\n",
      "\n",
      "nan nan\n",
      "l2 norm: nan\n",
      "l1 norm: nan\n",
      "Rbeta: nan\n",
      "(tensor(50.), tensor(nan))\n",
      "\n",
      "Train set: Avg. loss: nan, Accuracy: 256/512 (50%)\n",
      "\n",
      "nan nan\n",
      "l2 norm: nan\n",
      "l1 norm: nan\n",
      "Rbeta: nan\n",
      "\n",
      "Train set: Avg. loss: nan, Accuracy: 256/512 (50%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-344667686efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mRbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mrbetas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbetas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-103218507942>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(ker_size1, ker_size2, output_channels)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.000001\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# stop at 10^-6 loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mextract_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# After enough epochs, change the learning rate to be higher to expedite convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-bd1fa29ffc54>\u001b[0m in \u001b[0;36mextract_info\u001b[0;34m(network, show_photo)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtempimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_dim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mtempimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mbeta_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# Compute margin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-bd1fa29ffc54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mker_size2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mker_size1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'circular'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Circular padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ReLU activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run experiments and write data to a CSV\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "k_vals = [1, 3, 5, 8]\n",
    "Cout = [1, 2, 3, 4]\n",
    "\n",
    "for k in k_vals:\n",
    "    pairs = []\n",
    "    for c in Cout:\n",
    "        pairs.append((k, c))\n",
    "\n",
    "    betas = []\n",
    "    rbetas = []\n",
    "\n",
    "    for (k, output_channels) in pairs:\n",
    "        print(k, output_channels)\n",
    "        (Rbeta, beta) = experiment(k, k, output_channels)\n",
    "        rbetas.append(Rbeta)\n",
    "        betas.append(beta)\n",
    "\n",
    "    # Write rbetas \n",
    "    name =  str(k) + \"rbeta\" + str(Cout) + \"nonlinear\" + \".csv\"\n",
    "    pd.DataFrame(rbetas).to_csv(name, header=False, index=False)\n",
    "\n",
    "    # Write betas\n",
    "    for i in range(len(pairs)):\n",
    "        beta = betas[i]\n",
    "        beta = beta_array[j]\n",
    "        name = str(pairs[i]) + \"nonlinear\" + \".csv\"\n",
    "        print(str(pairs[i]))\n",
    "        pd.DataFrame(beta).to_csv(name, header=False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "greater-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earned-graphic",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1ae40f5c35b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classes1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-photography",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
